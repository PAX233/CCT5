{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, get_linear_schedule_with_warmup##在这里删除了adamw\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch.optim import AdamW#根据提示用的\n",
    "from tqdm import *\n",
    "from tqdm.auto import tqdm  # 使用auto以确保在不同环境下都能正常显示\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter #tensorboard\n",
    "import random\n",
    "\n",
    "writer0 = SummaryWriter(log_dir = './output/randeng/output')\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data, max_len=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        prompt_text, completion_text = self.data[idx]\n",
    "        input_encoding = self.tokenizer(prompt_text, max_length=self.max_len, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        target_encoding = self.tokenizer(completion_text, max_length=self.max_len, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        return {\n",
    "            'input_ids': input_encoding.input_ids.squeeze(),\n",
    "            'attention_mask': input_encoding.attention_mask.squeeze(),\n",
    "            'labels': target_encoding.input_ids.squeeze()\n",
    "        }\n",
    "\n",
    "# 加载数据并分割为训练集和测试集\n",
    "def load_and_split_data(tokenizer, file_path):\n",
    "    df = pd.read_excel(file_path, engine='openpyxl')\n",
    "    # df = df.iloc[:20]\n",
    "    data = [(str(row['问题']), str(row['答案'])) for _, row in df.iterrows()]\n",
    "    # train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    train_data = data\n",
    "    test_data = random.sample(data,len(data)//5)\n",
    "    print(\"---------data loaded---------\")\n",
    "    return CustomDataset(tokenizer, train_data), CustomDataset(tokenizer, test_data)\n",
    "\n",
    "def train_and_evaluate(model, tokenizer, file_path, epochs=50, batch_size=1, lr=5e-5):\n",
    "    train_dataset, test_dataset = load_and_split_data(tokenizer, file_path)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1)  # 测试时batch_size设为1简化处理\n",
    "    best_acc = 0\n",
    "    \n",
    "    cnt = 0\n",
    "    num_dict = [str(i) for i in range(100)]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        all_loss = 0.0\n",
    "        # 训练部分\n",
    "        # print(epoch)\n",
    "        model.train()\n",
    "        optimizer = AdamW(model.parameters(), lr=lr)\n",
    "        total_steps = len(train_loader) * epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(model.device)\n",
    "            attention_mask = batch['attention_mask'].to(model.device)\n",
    "            labels = batch['labels'].to(model.device)\n",
    "            labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            all_loss += loss.item()\n",
    "\n",
    "            # progress_bar.set_postfix(loss=loss.item())\n",
    "            #train_loss.append(loss.item())\n",
    "        writer0.add_scalar('train_loss', all_loss/len(train_loader), epoch)\n",
    "\n",
    "        # 评估部分\n",
    "        model.eval()\n",
    "        correct_predictions = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                input_ids = batch['input_ids'].to(model.device)\n",
    "                attention_mask = batch['attention_mask'].to(model.device)\n",
    "                outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                \n",
    "                _ = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = _.loss\n",
    "                all_loss += loss.item()\n",
    "\n",
    "                # 假设模型生成的第一个输出就是预测答案\n",
    "                predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                # predicted_text = predicted_text.replace(\"<extra_id_0>\",'')\n",
    "                # print(predicted_text)\n",
    "                \n",
    "                actual_text = tokenizer.decode(batch['labels'][0], skip_special_tokens=True)\n",
    "                # print(actual_text)\n",
    "\n",
    "                if predicted_text.strip().lower() == actual_text.strip().lower():\n",
    "                    correct_predictions += 1\n",
    "\n",
    "        acc = correct_predictions / len(test_loader)\n",
    "        print(f\"Test Accuracy: {acc:.4f}\")\n",
    "        writer0.add_scalar('test_acc', acc, epoch)\n",
    "        writer0.add_scalar('test_loss', all_loss/len(test_loader), epoch)\n",
    "        #return train_loss\n",
    "        \n",
    "        # 每次保存\n",
    "        if best_acc<acc:\n",
    "            best_acc = acc\n",
    "            save_path = \"./output/randeng\" #+ num_dict[cnt]\n",
    "            cnt += 1\n",
    "            if cnt == 10:\n",
    "                model.save_pretrained(\"./output/randeng20\")\n",
    "                tokenizer.save_pretrained(\"./output/randeng20\")\n",
    "            model.save_pretrained(save_path)\n",
    "            tokenizer.save_pretrained(save_path)\n",
    "            print(\"模型和分词器已保存。\")\n",
    "\n",
    "'''if __name__ == \"__main__\":\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"./model/flan-t5-base/\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"./model/flan-t5-base/\")\n",
    "\n",
    "    file_path = \"./test.xlsx\"\n",
    "    train_and_evaluate(model, tokenizer, file_path)'''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_path = \"./output/randeng10\"\n",
    "    # load_path = input('模型地址(模型保存在'./randeng'）'：)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(load_path)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(load_path).to('cuda')  # 将模型移动到GPU\n",
    "    print(\"---------model loaded---------\")\n",
    "    file_path = \"./data/数据全.xlsx\"\n",
    "    train_and_evaluate(model, tokenizer, file_path,20,1,1e-6)\n",
    "    print(\"---------train finished---------\")\n",
    "    \n",
    "    #plt.plot(loss)\n",
    "\n",
    "    # # 训练和评估完成后保存模型\n",
    "    # save_path = \"./output/randeng\"\n",
    "    # model.save_pretrained(save_path)\n",
    "    # tokenizer.save_pretrained(save_path)\n",
    "    # print(\"模型和分词器已保存。\")\n",
    "    writer0.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import *\n",
    "from tqdm.auto import tqdm\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "import torch\n",
    "from torch import cuda\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "path = './output/randeng10/'\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(path) \n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data, max_len=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        prompt_text, completion_text = self.data[idx]\n",
    "        input_encoding = self.tokenizer(prompt_text, max_length=self.max_len, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        target_encoding = self.tokenizer(completion_text, max_length=self.max_len, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        return {\n",
    "            'input_ids': input_encoding.input_ids.squeeze(),\n",
    "            'attention_mask': input_encoding.attention_mask.squeeze(),\n",
    "            'labels': target_encoding.input_ids.squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入问题: 2\n",
      "请输入轮数:  -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------data loaded---------\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0039370059967041016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Evaluating",
       "rate": null,
       "total": 4927,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1be3d99a244fa4b6dd8b2ac65dc00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4927 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----ended----\n"
     ]
    }
   ],
   "source": [
    "def postprocess(text):\n",
    "    return text.replace(\".\", \"\").replace('</>','')\n",
    "\n",
    "def answer_fn(text, top_k=50):\n",
    "    encoding = tokenizer(text=[text], truncation=True, padding=True, max_length=256, return_tensors=\"pt\").to(device)\n",
    "    out = model.generate(**encoding, return_dict_in_generate=True, output_scores=False, max_length=512,temperature=0.5,do_sample=True,repetition_penalty=1.4 ,top_k=top_k,top_p=0.95)\n",
    "    result = tokenizer.batch_decode(out[\"sequences\"], skip_special_tokens=True)\n",
    "    # print(type(out[\"sequences\"]))\n",
    "    return postprocess(result[0]) \n",
    "\n",
    "def test_data(file_path):\n",
    "    turns = int(input('请输入轮数: '))\n",
    "    df = pd.read_excel(file_path, engine='openpyxl')\n",
    "    if turns == -1 : turns = len(df)\n",
    "    df = df.sample(turns)\n",
    "    data = [(str(row['问题']), str(row['答案'])) for _, row in df.iterrows()]\n",
    "    print(\"---------data loaded---------\")\n",
    "    with open('test_data_output.txt','w') as w:\n",
    "        test_dataset = CustomDataset(tokenizer,data)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "        model.eval()\n",
    "        correct_predictions = 0\n",
    "        cnt = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                input_ids = batch['input_ids'].to(model.device)\n",
    "                attention_mask = batch['attention_mask'].to(model.device)\n",
    "                outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "                # 假设模型生成的第一个输出就是预测答案\n",
    "                result = tokenizer.decode(outputs[0], skip_special_tokens=True).strip().lower()\n",
    "                # predicted_text = predicted_text.replace(\"<extra_id_0>\",'')\n",
    "                # print(predicted_text)\n",
    "                \n",
    "                a = tokenizer.decode(batch['labels'][0], skip_special_tokens=True).strip().lower()\n",
    "                # print(actual_text)\n",
    "                q = data[cnt][0]\n",
    "                \n",
    "                # w.write(f\"问题: {q}\\n\")\n",
    "                # w.write(f\"答案: {a}\\n\")\n",
    "                # w.write(f\"生成: {result}\\n\")\n",
    "                # w.write(\"*\"*100)\n",
    "                # w.write('\\n')\n",
    "\n",
    "                if result == a:\n",
    "                    correct_predictions += 1\n",
    "                else:\n",
    "                    w.write(f\"{cnt}\\n\")\n",
    "                \n",
    "                cnt+=1\n",
    "                if cnt == turns:\n",
    "                    break\n",
    "\n",
    "        acc = correct_predictions / cnt\n",
    "        w.write(f\"Test Accuracy: {(acc):.4f}\")\n",
    "        print(\"----ended----\")\n",
    "        # for q, a in tqdm(data, desc=f\"Testing\"):\n",
    "        #     w.write(f\"问题: {q}\\n\")\n",
    "        #     # a = actual_text = tokenizer.decode(a, skip_special_tokens=True)\n",
    "        #     w.write(f\"答案: {a}\\n\")\n",
    "        #     result=answer_fn(q, top_k=50)\n",
    "        #     w.write(f\"生成: {result}\\n\")\n",
    "        #     w.write(\"*\"*100)\n",
    "        #     w.write('\\n')\n",
    "        #     if result.strip().lower() == a.strip().lower():\n",
    "        #         acc += 1\n",
    "        # w.write(f\"Test Accuracy: {(acc / turns):.4f}\")\n",
    "def eval_data(file_path,turns = -1):\n",
    "    df = pd.read_excel(file_path, engine='openpyxl')\n",
    "    if turns == -1:\n",
    "        turns = int(input(f'请输入测试数: {len(df)}: '))\n",
    "        if turns > len(df):\n",
    "            turns = len(df)\n",
    "        print(f\"测试数目：{turns}\")\n",
    "        print('*'*100)\n",
    "    df = df.sample(turns)\n",
    "    data = [(str(row['问题']), str(row['答案'])) for _, row in df.iterrows()]\n",
    "    # data = data.iloc[:100]\n",
    "    acc = 0\n",
    "    for q, a in tqdm(data, desc=f\"Evaluating \") :\n",
    "        result=answer_fn(q, top_k=50)\n",
    "        if result.strip().lower() == a.strip().lower():\n",
    "            acc += 1\n",
    "            \n",
    "    print(f\"Test Accuracy: {acc / len(data):.4f}\")\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "# test_path = './data/webQA/me_train.xlsx'\n",
    "test_path = './data/数据全.xlsx'\n",
    "\n",
    "while True:\n",
    "    text = input('请输入问题:')\n",
    "    # test_path = input('输入测试数据地址:')\n",
    "    if text == 'q':\n",
    "        break\n",
    "    elif text == '2':\n",
    "        test_data(test_path)\n",
    "        break\n",
    "    elif text == '3':\n",
    "        eval_data(test_path)\n",
    "        break\n",
    "    elif text == '4':\n",
    "        eval_data(test_path,turns=100)\n",
    "        break\n",
    "    result=answer_fn(text, top_k=50)\n",
    "    print(\"模型生成:\",result)\n",
    "    print('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- ----------------\n",
      "absl-py                       0.14.1\n",
      "alabaster                     0.7.12\n",
      "anyio                         3.6.2\n",
      "apex                          0.1\n",
      "appdirs                       1.4.4\n",
      "argon2-cffi                   21.1.0\n",
      "asgiref                       3.4.1\n",
      "attrs                         21.2.0\n",
      "audioread                     2.1.9\n",
      "Babel                         2.11.0\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "beautifulsoup4                4.10.0\n",
      "bleach                        4.1.0\n",
      "blis                          0.7.4\n",
      "brotlipy                      0.7.0\n",
      "cachetools                    4.2.4\n",
      "catalogue                     2.0.6\n",
      "certifi                       2024.2.2\n",
      "cffi                          1.14.6\n",
      "chardet                       4.0.0\n",
      "charset-normalizer            2.0.0\n",
      "click                         8.0.1\n",
      "cloudpickle                   2.2.1\n",
      "codecov                       2.1.12\n",
      "colorama                      0.4.4\n",
      "comm                          0.2.2\n",
      "conda                         4.14.0\n",
      "conda-build                   3.21.4\n",
      "conda-package-handling        1.7.3\n",
      "coverage                      6.0.1\n",
      "cryptography                  3.4.7\n",
      "cycler                        0.10.0\n",
      "cymem                         2.0.5\n",
      "Cython                        0.29.24\n",
      "dataclasses                   0.8\n",
      "debugpy                       1.8.1\n",
      "decorator                     5.1.0\n",
      "defusedxml                    0.7.1\n",
      "Django                        3.2.6\n",
      "docutils                      0.17.1\n",
      "entrypoints                   0.3\n",
      "et-xmlfile                    1.1.0\n",
      "expecttest                    0.1.3\n",
      "fastjsonschema                2.16.2\n",
      "filelock                      3.3.0\n",
      "flake8                        3.7.9\n",
      "Flask                         2.0.2\n",
      "fsspec                        2024.3.1\n",
      "future                        0.18.2\n",
      "glob2                         0.7\n",
      "google-auth                   1.35.0\n",
      "google-auth-oauthlib          0.4.6\n",
      "graphsurgeon                  0.4.5\n",
      "grpcio                        1.41.0\n",
      "gunicorn                      20.1.0\n",
      "h11                           0.12.0\n",
      "horovod                       0.28.1\n",
      "httptools                     0.2.0\n",
      "huggingface-hub               0.22.1\n",
      "Hydra                         2.5\n",
      "hypothesis                    4.50.8\n",
      "idna                          3.1\n",
      "imagesize                     1.2.0\n",
      "importlib-metadata            6.0.0\n",
      "importlib-resources           5.10.2\n",
      "iniconfig                     1.1.1\n",
      "iopath                        0.1.9\n",
      "ipykernel                     6.29.4\n",
      "ipython                       7.28.0\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    8.1.2\n",
      "itsdangerous                  2.0.1\n",
      "jedi                          0.18.0\n",
      "Jinja2                        3.1.2\n",
      "joblib                        1.1.0\n",
      "json5                         0.9.6\n",
      "jsonschema                    4.17.3\n",
      "jupyter                       1.0.0\n",
      "jupyter_client                7.4.9\n",
      "jupyter-console               6.6.3\n",
      "jupyter_core                  5.1.5\n",
      "jupyter-server                1.23.5\n",
      "jupyter-tensorboard           0.2.0\n",
      "jupyterlab                    3.2.5\n",
      "jupyterlab-pygments           0.2.2\n",
      "jupyterlab_server             2.19.0\n",
      "jupyterlab_widgets            3.0.10\n",
      "jupytext                      1.14.4\n",
      "kiwisolver                    1.3.2\n",
      "libarchive-c                  3.1\n",
      "librosa                       0.8.1\n",
      "llvmlite                      0.35.0\n",
      "lmdb                          1.2.1\n",
      "Markdown                      3.3.4\n",
      "markdown-it-py                1.1.0\n",
      "MarkupSafe                    2.0.1\n",
      "matplotlib                    3.4.3\n",
      "matplotlib-inline             0.1.3\n",
      "mccabe                        0.6.1\n",
      "mdit-py-plugins               0.2.8\n",
      "mistune                       2.0.4\n",
      "mock                          4.0.3\n",
      "murmurhash                    1.0.5\n",
      "nbclassic                     0.5.1\n",
      "nbclient                      0.5.4\n",
      "nbconvert                     7.2.9\n",
      "nbformat                      5.7.3\n",
      "nest-asyncio                  1.5.6\n",
      "networkx                      2.0\n",
      "nltk                          3.6.4\n",
      "notebook                      6.4.1\n",
      "notebook_shim                 0.2.2\n",
      "numba                         0.52.0\n",
      "numpy                         1.20.3\n",
      "nvidia-dali-cuda110           1.6.0\n",
      "nvidia-dlprof-pytorch-nvtx    1.6.0\n",
      "nvidia-dlprofviewer           1.6.0\n",
      "nvidia-pyindex                1.0.9\n",
      "oauthlib                      3.1.1\n",
      "onnx                          1.8.204\n",
      "openpyxl                      3.1.2\n",
      "packaging                     23.0\n",
      "pandas                        2.0.3\n",
      "pandocfilters                 1.5.0\n",
      "parso                         0.8.2\n",
      "pathy                         0.6.0\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        8.2.0\n",
      "pip                           21.2.4\n",
      "pkginfo                       1.7.1\n",
      "pkgutil_resolve_name          1.3.10\n",
      "platformdirs                  2.6.2\n",
      "pluggy                        1.0.0\n",
      "polygraphy                    0.33.0\n",
      "pooch                         1.5.1\n",
      "portalocker                   2.3.2\n",
      "preshed                       3.0.5\n",
      "prettytable                   2.2.1\n",
      "prometheus-client             0.11.0\n",
      "prompt-toolkit                3.0.43\n",
      "protobuf                      3.18.1\n",
      "psutil                        5.8.0\n",
      "ptyprocess                    0.7.0\n",
      "py                            1.10.0\n",
      "pyasn1                        0.4.8\n",
      "pyasn1-modules                0.2.8\n",
      "pybind11                      2.8.0\n",
      "pycocotools                   2.0+nv0.5.1\n",
      "pycodestyle                   2.5.0\n",
      "pycosat                       0.6.3\n",
      "pycparser                     2.20\n",
      "pydantic                      1.8.2\n",
      "pydot                         1.4.2\n",
      "pyflakes                      2.1.1\n",
      "Pygments                      2.10.0\n",
      "pyOpenSSL                     20.0.1\n",
      "pyparsing                     2.4.7\n",
      "pyrsistent                    0.18.0\n",
      "PySocks                       1.7.1\n",
      "pytest                        6.2.5\n",
      "pytest-cov                    3.0.0\n",
      "pytest-pythonpath             0.7.3\n",
      "python-dateutil               2.8.2\n",
      "python-dotenv                 0.19.1\n",
      "python-hostlist               1.21\n",
      "python-nvd3                   0.15.0\n",
      "python-slugify                5.0.2\n",
      "pytorch-quantization          2.1.0\n",
      "pytz                          2021.3\n",
      "PyYAML                        5.4.1\n",
      "pyzmq                         25.0.0\n",
      "qtconsole                     5.5.1\n",
      "QtPy                          2.4.1\n",
      "regex                         2021.10.8\n",
      "requests                      2.28.2\n",
      "requests-oauthlib             1.3.0\n",
      "resampy                       0.2.2\n",
      "revtok                        0.0.3\n",
      "rsa                           4.7.2\n",
      "ruamel-yaml-conda             0.15.80\n",
      "sacremoses                    0.0.46\n",
      "safetensors                   0.4.2\n",
      "scikit-learn                  1.0\n",
      "scipy                         1.6.3\n",
      "Send2Trash                    1.8.0\n",
      "sentencepiece                 0.2.0\n",
      "setuptools                    58.2.0\n",
      "shellingham                   1.4.0\n",
      "six                           1.16.0\n",
      "smart-open                    5.2.1\n",
      "sniffio                       1.3.0\n",
      "snowballstemmer               2.1.0\n",
      "SoundFile                     0.10.3.post1\n",
      "soupsieve                     2.0.1\n",
      "spacy                         3.1.3\n",
      "spacy-legacy                  3.0.8\n",
      "Sphinx                        4.2.0\n",
      "sphinx-glpi-theme             0.3\n",
      "sphinx-rtd-theme              1.0.0\n",
      "sphinxcontrib-applehelp       1.0.2\n",
      "sphinxcontrib-devhelp         1.0.2\n",
      "sphinxcontrib-htmlhelp        2.0.0\n",
      "sphinxcontrib-jsmath          1.0.1\n",
      "sphinxcontrib-qthelp          1.0.3\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "sqlparse                      0.4.2\n",
      "srsly                         2.4.1\n",
      "tabulate                      0.8.9\n",
      "tensorboard                   2.6.0\n",
      "tensorboard-data-server       0.6.1\n",
      "tensorboard-plugin-wit        1.8.0\n",
      "tensorrt                      8.0.3.4\n",
      "terminado                     0.12.1\n",
      "testpath                      0.5.0\n",
      "text-unidecode                1.3\n",
      "thinc                         8.0.10\n",
      "threadpoolctl                 3.0.0\n",
      "tinycss2                      1.2.1\n",
      "tokenizers                    0.15.2\n",
      "toml                          0.10.2\n",
      "tomli                         1.2.1\n",
      "toolz                         0.12.1\n",
      "torch                         1.10.0a0+0aef44c\n",
      "torchtext                     0.11.0a0\n",
      "torchvision                   0.11.0a0\n",
      "tornado                       6.2\n",
      "tqdm                          4.62.3\n",
      "traitlets                     5.8.1\n",
      "transformers                  4.39.2\n",
      "typer                         0.4.0\n",
      "typing-extensions             3.10.0.2\n",
      "tzdata                        2024.1\n",
      "uff                           0.6.9\n",
      "urllib3                       1.26.7\n",
      "uvicorn                       0.15.0\n",
      "uvloop                        0.16.0\n",
      "wasabi                        0.8.2\n",
      "watchgod                      0.7\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "websocket-client              1.5.0\n",
      "websockets                    10.0\n",
      "Werkzeug                      2.0.2\n",
      "wheel                         0.37.0\n",
      "whitenoise                    5.3.0\n",
      "widgetsnbextension            4.0.10\n",
      "zipp                          3.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
